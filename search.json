[
  {
    "objectID": "submit.html",
    "href": "submit.html",
    "title": "How to submit",
    "section": "",
    "text": "Submissions are handled by an Action Editor who will assign each submission to three expert reviewers. Review proceeds as a dialogue between authors and reviewers, with the goal of improving the work. Authors can expect that their submissions will not be rejected over easily fixable technicalities.\nAll submitted work, reviews, and discussions will by default be publicly available for other researchers to use. To encourage accountability, editors’ names are listed on the articles they accept, and reviewers may choose to be named or anonymous. All submissions and their accompanying reviews and discussions remain accessible whether or not an article is accepted.\nJoVI encourages registered reports, which follow a two-stage submission and review process. In the first stage, authors submit a paper that contains all plans, methods, and research questions, prior to any data collection. Through dialogue and discussion, reviewers and authors agree on revised plans, methods, and research questions. Then authors can collect and analyze data and write the final version of the paper, which will get a lightweight second-stage review by the same reviewers (except in extenuating circumstances).\nJoVI has two submission tracks: the traditional track and the experimental (“Github”) track."
  },
  {
    "objectID": "submit.html#traditional",
    "href": "submit.html#traditional",
    "title": "How to submit",
    "section": "Traditional track",
    "text": "Traditional track\nYou may prepare your paper with any academic paper template; we recommend the ACM template or the IEEE TVCG template.\nSubmission for the traditional track proceeds via the OJS submission system, hosted courtesy of the Aalborg University Library. Please create an OJS account, preferably using your default institutional email address, and follow the instructions on OJS to submit your paper and supplementary materials.\nTo submit:\n\nPlease read the Author Guidelines, even if you are a seasoned HCI/VIS researcher. JoVI’s process and expectations may be a bit different from what you are used to.\nStart:\n\nGo to JoVI’s OJS page\nCreate an account and/or log in, if needed\nRead and tick all checkboxes\nClick Save and continue\n\nUpload submission:\n\nClick Add file, upload main PDF\nSelect “article text” as type\nUpload other files, if desired. For example, if you are submitting anonymously, you may need to upload non-anonymous versions of some information for the editors to review. See the author guide.\nClick Save and continue\n\nEnter Metadata:\n\nAdd title and abstract\nAdd co-authors: click add contributor, fill form\n\nSelect Author as role\nIf you create accounts for your co-authors, we recommend ticking Include contributor in browse lists so that co-authors’ accounts can be found later in search boxes.\n\nOptional: fill in extra metadata\nClick Save and continue\n\nConfirmation:\n\nClick Finish submission"
  },
  {
    "objectID": "submit.html#experimental",
    "href": "submit.html#experimental",
    "title": "How to submit",
    "section": "Experimental (“Github”) track",
    "text": "Experimental (“Github”) track\nThe experimental track is an alternative submission and review process that manifests our commitment to experimenting with review processes. This track is less well-defined, in part because we wish it to evolve with authors as we use it.\nAll papers in the “Github” track must be written in Quarto, a markdown-based computational notebook format. Quarto can be used with documents written in a variety of forms (RMarkdown, Jupyter notebook, Word, Latex), and supports embedded computation (in many languages, including R, python, and Julia) and interactivity (using JavaScript / Observable).\nAll review on the experimental track will proceed as Github issues and pull requests, and published papers on this track can be updated using pull requests, even after publication.\nTo submit to the experimental track, write your paper in quarto using this template and then email us your paper information and a link to your repository at submit@journalovi.org."
  },
  {
    "objectID": "structured-abstract-examples.html",
    "href": "structured-abstract-examples.html",
    "title": "Examples of structured abstracts",
    "section": "",
    "text": "Below are several examples of structured abstracts written based on existing papers in order to demonstrate their use.\nSee the top of the JoVI article template for the structured abstract template."
  },
  {
    "objectID": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "href": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "title": "Examples of structured abstracts",
    "section": "Perceptual proxies (empirical)",
    "text": "Perceptual proxies (empirical)\nBased on Perceptual proxies for extracting averages in data visualization\n\nIntroduction\nAcross science, education, and business, we process and communicate data visually. One bedrock finding in data visualization research is a hierarchy of precision for perceptual encodings of data, e.g., that encoding data with Cartesian positions allows more precise comparisons than encoding with sizes. But this hierarchy has only been tested for single value comparisons, under the assumption that those lessons would extrapolate to multi-value comparisons.\n\n\nData Collection or Source\nWe ran four within-subject behavioral experiments (three preregistered) to measure subjects’ ability to differentiate single values or set averages. The experiments used a staircase method to measure accuracy when comparing pairs of dot plots (position), floating bar graphs (length), or regular bar graphs (position + length).\n\n\nData Analysis\nWe used the stopping point of the staircase to estimate the just noticeable difference and ran within-subject anovas and t-test to estimate differences between (1) chart types, (2) single values vs. set averages, and (3) set sizes.\n\n\nAnalysis Results\nResults include: (1) Confirming known findings in the visualization literature, the results showed that single-value comparison was least precise with floating bar graphs (length only). (2) However, when comparing averages across multiple data points, the discriminability was indistinguishable between chart types. (3) An exploratory analysis found that comparisons between different set sizes reduced accuracy but not reliably for all chart types.\n\n\nConclusion\nViewers compare values using surprisingly primitive perceptual cues, e.g., the summed area of bars in a bar graph. These results highlight a critical need to study a broader constellation of visual cues that mediate the patterns that we can see in data, across visualization types and tasks.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "href": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "title": "Examples of structured abstracts",
    "section": "Open practices in vis (empirical)",
    "text": "Open practices in vis (empirical)\nBased on Open practices in visualization research\n\nIntroduction\nTwo fundamental tenets of scientific research are that it can be scrutinized and built-upon. Both require that the collected data and supporting materials be shared, so others can examine, reuse, and extend them. Assessing the accessibility of these components and the paper itself can serve as a proxy for the reliability, replicability, and applicability of a field’s research.\n\n\nData Collection or Source\nI checked all papers published in VIS in 2017 to see which were available on a preprint repository, included a preregistration, included data collection materials, included raw data, or included computation/analysis materials.\n\n\nData Analysis\nIn an exploratory analysis of all VIS publications in 2017, I calculated the proportion of papers with a preprint and open practices on a reliable open access repository or a website without long-term availability.\n\n\nAnalysis Results\nA minority of published articles are available on an open access server, and extremely few included additional research materials on an open and reliable repository. The availability also varied by conference track.\n\n\nConclusion\nThe lack of open practices may severely hamper the ability to scrutinize, replicate, or reproduce visualization research. The paper provides suggestions for authors, reviewers, and editors to improve the poor state of open practices in the field.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#explorable-multiverse-technique",
    "href": "structured-abstract-examples.html#explorable-multiverse-technique",
    "title": "Examples of structured abstracts",
    "section": "Explorable multiverse (technique)",
    "text": "Explorable multiverse (technique)\nBased on Increasing the Transparency of Research Papers with Explorable Multiverse Analyses\n\nIntroduction\nWe present explorable multiverse analysis reports (EMARs), a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two ideas: multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation.\n\n\nImplementation\nWe use R scripts to build EMARs by pre-computing analysis results from every universe from a combination of all analysis parameters in a given multiverse. The output from those scripts is then presented using interactive HTML+JavaScript templates.\n\n\nDemonstration\nWe prototype five example EMARs by re-analyzing existing papers and building interactive papers to demonstrate different interactive approaches to communicating multiverses. We show how combining multiverse analysis and explorable explanations might complement existing reporting approaches and constitute a step towards more transparent research papers.\nBased on these examples and existing literature on multiverse analysis, we develop a design space for multiverse analysis reports. Our design space describes analysis parameters, analysis options, and multiplexing and aggregation techniques for summarizing and communicating multiverses. We identify several challenges to multiverse construction, including identifying simple end goals that can be multiplexed across universes (which can be easier with single statistics than entire plots, for example), and provide recommendations for writing conclusions in papers that span multiverses (to avoid authors/readers simply selecting desired results).\n\n\nConclusion\nThe development of tools to facilitate the multiverse analysis process within analysts’ workflows remains a substantial challenge: our prototypes consist of custom R scripts and HTML templates that require significant technical expertise to develop. Automating these workflows for data analysts is an important next step.\n\n\nMaterials\nSee live demo here. [NOTE: for JoVI, a backup link to a permanent repository should also be included with live demo links]"
  },
  {
    "objectID": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "href": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "title": "Examples of structured abstracts",
    "section": "BinarySwipes (technique + user study)",
    "text": "BinarySwipes (technique + user study)\nBased on BinarySwipes: Fast List Search on Small Touchscreens (straightforward UI technique & user study) [Florian]\n\nIntroduction\nWe present BinarySwipes, an interaction technique based on binary search which is designed to speed up list search tasks on space-constrained touchscreens.\nSmartwatches and other wearables generally have small screens, thereby complicating touch-based interaction. Selection from a long list, eg to locate a contact or a music track, is particularly cumbersome due to the limited interaction space.\n\n\nImplementation\nTBD\n\n\nDemonstration\nTBD\n\n\nData Collection or Source\nWe evaluate a prototypical implementation of BinarySwipes on a smartwatch with 21 participants in a controlled user study. We measure task completion time, error rate, and self-reported NASA TLX values.\n\n\nData Analysis\nWe analyze our data with respect to normal distribution (Shapiro-Wilk) and statistically significant differences between conditions (ANOVA with post-hoc Tukey HSD, Bonferroni correction).\n\n\nAnalysis Results\nResults from our evaluation show improved performance over a plain linear search on lists with 100, 200 and 500 entries, but also increased mental load on the users.\n\n\nConclusion\nBinarySwipes is a viable technique for quickly locating known items in long lists, but challenges remain for exploratory search, or when the presence of the item is not known in advance.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Journal of Visualization and Interaction",
    "section": "",
    "text": "The Journal of Visualization and Interaction (JoVI) is a venue for publishing scholarly work related to the fields of visualization and human-computer interaction. Contributions to the journal include research in:\n\nhow people understand and interact with information and technology,\ninnovations in interaction techniques, interactive systems, or tools,\nsystematic literature reviews,\nreplication studies or reinterpretations of existing work,\nand commentary on existing publications.\n\nCross-disciplinary work from other fields such as statistics or psychology, which is relevant to the fields of visualization or human-computer interaction is also welcome.\nJoVI’s missions are the following:"
  },
  {
    "objectID": "index.html#what-is-jovi",
    "href": "index.html#what-is-jovi",
    "title": "The Journal of Visualization and Interaction",
    "section": "",
    "text": "The Journal of Visualization and Interaction (JoVI) is a venue for publishing scholarly work related to the fields of visualization and human-computer interaction. Contributions to the journal include research in:\n\nhow people understand and interact with information and technology,\ninnovations in interaction techniques, interactive systems, or tools,\nsystematic literature reviews,\nreplication studies or reinterpretations of existing work,\nand commentary on existing publications.\n\nCross-disciplinary work from other fields such as statistics or psychology, which is relevant to the fields of visualization or human-computer interaction is also welcome.\nJoVI’s missions are the following:"
  },
  {
    "objectID": "index.html#open",
    "href": "index.html#open",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open by default",
    "text": "Open by default\nJoVI strongly supports transparency and openness and implements it as a default to enable readers to scrutinize and build on the research . All published manuscripts are open access. For any empirical components, manuscripts must make all data and reasoning available in ways that invite scrutiny, so that subsequent researchers can assess claims, reuse methods and materials, and build upon findings. For any computational components, all code needs to be reproducible within a reasonable effort. When ethical concerns prevent submissions to meet these requirements, the manuscript must clearly describe the characteristics of these artifacts and adequately justify the tradeoff between openness and ethics."
  },
  {
    "objectID": "index.html#open-review",
    "href": "index.html#open-review",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open review, comments, and continued conversation",
    "text": "Open review, comments, and continued conversation\nAll submitted work, reviews, and discussions will by default be publicly available for other researchers to use. To encourage accountability, editors’ names are listed on the articles they accept, and reviewers may choose to be named or anonymous . All submissions and their accompanying reviews and discussions remain accessible whether or not an article is accepted. To foster discussions that go beyond the initial reviewer/author exchanges, we welcome post-publication commentaries on articles."
  },
  {
    "objectID": "index.html#knowledge",
    "href": "index.html#knowledge",
    "title": "The Journal of Visualization and Interaction",
    "section": "Knowledge over novelty",
    "text": "Knowledge over novelty\nWe prioritize how research advances knowledge rather than superficial novelty. Reviews aim to evaluate the credibility of a manuscript’s claims and the clarity of its evidence. Contributions of interaction techniques or interactive systems may meet this knowledge criterion through existence proofs. For empirical works, JoVI encourages registered reports —the reviewing of study plans prior to execution—and has a process to support this type of contribution. The discourses on the merit of the manuscripts must be justified by evidence, credible literature, or cogent argument."
  },
  {
    "objectID": "index.html#humane",
    "href": "index.html#humane",
    "title": "The Journal of Visualization and Interaction",
    "section": "A more humane process, respectful of everyone’s time",
    "text": "A more humane process, respectful of everyone’s time\nJoVI respects the time and effort of both authors and reviewers, and aims for a collaborative, humane review process. To that end, JoVI does not publish a limited number of manuscripts and does not seek to have a certain rejection rate. Instead, review proceeds as a back and forth between authors and reviewers, with the goal of improving the work. Authors can expect that their submissions will not be rejected over easily fixable technicalities."
  },
  {
    "objectID": "index.html#ambitions",
    "href": "index.html#ambitions",
    "title": "The Journal of Visualization and Interaction",
    "section": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents",
    "text": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents\nIn addition to the missions above, JoVI also aspires to be a platform for other improvements of scholarly communication. On an alternate, optional submission track, we will continually experiment with new article formats (including modern, interactive formats), new review processes, and articles as living documents. This experimentation will be motivated by re-conceptualizing peer review as a humane, constructive process aimed at improving work rather than gatekeeping."
  },
  {
    "objectID": "index.html#acks",
    "href": "index.html#acks",
    "title": "The Journal of Visualization and Interaction",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the following people (in alphabetical order) who provided input on earlier versions of our mission statement: Leilani Battle, Pierre Dragicevic, Niklas Elmqvist, Jean-Daniel Fekete, Maximilian Häussler, Steve Haroz, Yvonne Jansen, Tamara Munzner, Kimberly Quinn, Raphael Wimmer."
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "code-of-conduct.html#our-pledge",
    "href": "code-of-conduct.html#our-pledge",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "code-of-conduct.html#our-standards",
    "href": "code-of-conduct.html#our-standards",
    "title": "Code of conduct",
    "section": "Our standards",
    "text": "Our standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "code-of-conduct.html#enforcement-responsibilities",
    "href": "code-of-conduct.html#enforcement-responsibilities",
    "title": "Code of conduct",
    "section": "Enforcement responsibilities",
    "text": "Enforcement responsibilities\nCommunity leaders, including but not limited to the editorial board and associate editors, are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "code-of-conduct.html#scope",
    "href": "code-of-conduct.html#scope",
    "title": "Code of conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, acting as an appointed representative at an online or offline event, or posting public reviews, issues, or comments on submissions."
  },
  {
    "objectID": "code-of-conduct.html#enforcement",
    "href": "code-of-conduct.html#enforcement",
    "title": "Code of conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at the JoVI Code of Conduct Incident Report Form. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "code-of-conduct.html#enforcement-guidelines",
    "href": "code-of-conduct.html#enforcement-guidelines",
    "title": "Code of conduct",
    "section": "Enforcement guidelines",
    "text": "Enforcement guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\nCorrection\n\nCommunity Impact\nUse of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\n\n\nConsequence\nA private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. Editors may require that the language of a review or response be changed before allowing the message to proceed to other parties.\n\n\n\nWarning\n\nCommunity Impact\nA violation through a single incident or series of actions.\n\n\nConsequence\nA warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nTemporary ban\n\nCommunity Impact\nA serious violation of community standards, including sustained inappropriate behavior.\n\n\nConsequence\nA temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nPermanent ban\n\nCommunity Impact\nDemonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\n\n\nConsequence\nA permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "code-of-conduct.html#attribution",
    "href": "code-of-conduct.html#attribution",
    "title": "Code of conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about the Contributor Covenant, see the FAQ. Translations are available here."
  },
  {
    "objectID": "reviewer-guide.html",
    "href": "reviewer-guide.html",
    "title": "Reviewer guidelines",
    "section": "",
    "text": "Thank you for considering reviewing for the Journal of Visualization and Interaction (JoVI)! As with any peer-reviewed journal or conference, it is our volunteer reviewers who make it possible for us to publish valid and high-quality scientific papers. Reviewing for JoVI is in many ways the same as in reviewing for any other peer-reviewed venue. In this document, we will describe the overall review process, focusing in particular on topics that may be different from a typical journal or conference."
  },
  {
    "objectID": "reviewer-guide.html#before-agreeing-to-review",
    "href": "reviewer-guide.html#before-agreeing-to-review",
    "title": "Reviewer guidelines",
    "section": "Before Agreeing to Review",
    "text": "Before Agreeing to Review\n\nConfidentiality\nBy agreeing to review for JoVI, you also agree to maintain the confidentiality of all materials shared with you during the review process. Do not use any of the ideas, concepts, or techniques disclosed to you as part of the review process in your own research until they have been made public.\n\n\nAnonymity and Identity\nAuthors can choose to list their names or be anonymous during the reviewing process. We acknowledge the potential issues with unblinded review. For further discussion and feedback please see issue #16.\nA reviewer is still eligible to review if they know who the authors are due to seeing the work on social media or seeing a prior version of the work. However, reviewers should not “play detective” and actively seek anonymous author identities. In other words, please do not search for paper titles, open-source project names, or preprints during the review.\nExternal reviewers can choose to be named or to remain anonymous by simply choosing whether or not to sign their review (e.g., “signed, Jane Doe”). Signing reviews is encouraged, especially for thoughtful and thorough reviews.\nFor accountability, the action editor is not anonymous.\n\n\nConflicts of Interest\nPeer review is based on unbiased and fair reviewing practices. Conflicts of interest (COIs) are situations where a reviewer is unable to (or is perceived to be unable to) uphold a lack of bias and fairness. To prevent COIs from impacting the process, JoVI abides by the general ACM guidelines for conflicts of interest. Generally speaking, if you feel unable to give an unbiased and fair opinion on a submission given its authors or their affiliations, you should not review it.\nExample conflicts inappropriate for reviewing:\n\nPh.D. or postdoctoral mentor or mentee;\nFamily or close personal relationship;\nCo-author on a peer-reviewed paper within the last 2 years;\nCurrent collaborator on in-progress work or work under review; and\nAnyone at the same institution (excluding different branches or campuses).\nProfessional friendship or animosity."
  },
  {
    "objectID": "reviewer-guide.html#first-impression",
    "href": "reviewer-guide.html#first-impression",
    "title": "Reviewer guidelines",
    "section": "First Impression",
    "text": "First Impression\n\nPaper Length\nJoVI enforces no page limits or writing style on papers, but papers which are overly long or difficult to read are wasteful of both readers’ and reviewers’ time. The page length of a paper should be commensurate with its contribution, so reviewers are encouraged to point out parts of the submission that can be trimmed. The length of a manuscript should not however be used to recommend its rejection — rather it is a reason to suggest revision.\nThe corollary is that there is also no minimum page count for JoVI papers; short papers are encouraged if they represent succinctly described and useful ideas of general value to the visualization and interaction community."
  },
  {
    "objectID": "reviewer-guide.html#key-assessment-criteria",
    "href": "reviewer-guide.html#key-assessment-criteria",
    "title": "Reviewer guidelines",
    "section": "Key Assessment Criteria",
    "text": "Key Assessment Criteria\n\nKnowledge\nThe submission must prove its merit in advancing knowledge related to the fields of visualization and human-computer interaction. Knowledge advancement can be achieved in several ways, including but not limited to:\n\nEmpirical studies investigate research questions that have not been considered before\nReplication studies improve or challenge the confidence of the field about existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population, etc)\nSystems or design research expands the capacity of people to do useful things that what was not previously possible\nSystematic literature reviews enables the field to synthesize knowledge across existing work\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo\n\n\n\nValidity\nWhen reviewing JoVI papers, focus on the questions and claims in the manuscript:\n\nAre those claims and questions clearly communicated?\nAre the claims supported with evidence?\nDo the claims generalize beyond a narrow case?\nConstruct validity: If evidence is collected via an experiment or simulation, does the collected evidence actually answer the question and support the claim? Does it support a stronger, weaker, or different claim? For example, if a paper only measures computational performance, it should not include claims about improved human behavioral performance.\nExternal validity: If there is a generalization beyond the manuscript, is that generalization supported with evidence?\nAnalytical validity: If there is any computational or statistical analysis, is it an appropriate match for the research question? Is it reported in an accurate and interpretable way?\n\nNote: While lack of novelty is not a concern at this journal, failure to contrast with very similar work may be problematic.\n\n\nOpenness and Transparency\nAll JoVI submissions are required to include all material needed to properly scrutinize and build on the research. For any empirical components, manuscripts must make all data and reasoning available in ways that invite scrutiny, so that subsequent researchers can assess claims, reuse methods and materials, and build upon findings. For any computational components, all code needs to be reproducible within a reasonable effort. When ethical concerns prevent submissions to meet these requirements, the manuscript must clearly describe the characteristics of these artifacts and adequately justify the tradeoff between openness and ethics.\nExamples of materials that should be included, except where justified as above: experiment code, software and hardware components of prototypes, stimuli, interview guides, transcripts, raw empirical data, analysis scripts, and URLs to preregistrations. For full details, see level 2 of the TOP guidelines (summary table and thefull guidelines).\nAs a reviewer, you are simply asked to check that the materials are present and accessible. You are encouraged (but not required) to check the validity of any part of the submission using its replication and reproducibility materials. If you do so, you should mention it in your review.\nIf you cannot access any of the material, you can stop the review to avoid wasting time. Tell the action editor immediately, and they will then contact the author to remedy the problem. The action editor will confirm, ask the authors to fix the problem, and reply to the reviewers once the review process can continue.\nUnder special circumstances, a submission may state the reason that material cannot be shared (e.g., for protecting participants’ identity). Such a statement must appear in the body of the paper. Reviewers and editors must make a judgment call as to whether the authors shared as much as possible and whether the rationale is acceptable.\nExamples:\n\nAcceptable: Sharing all of the data except subject-identifying columns.\nAcceptable: Putting any necessary identifiable information, transcripts, and recordings in a protected-access repository that requires following an ethical-vetting procedure to access.\nUnacceptable: Authors claim that material is their own intellectual property or will not share it due to commercial purposes.\nUnacceptable: Only sharing aggregated data and omitting the raw data and data aggregation code without stating why.\nUnacceptable: Authors told their IRB that they would not share the material despite it appearing fully anonymized."
  },
  {
    "objectID": "reviewer-guide.html#writing-your-review",
    "href": "reviewer-guide.html#writing-your-review",
    "title": "Reviewer guidelines",
    "section": "Writing Your Review",
    "text": "Writing Your Review\nJoVI reviews should be thorough but kind: aim for completeness and clarity of critique, but also think about how the authors will read your review (write the kind of review you would appreciate receiving). JoVI does not have a set rejection rate, so any work meeting our key criteria (above) should be a candidate for acceptance.\n\nModular Reviews\nTo facilitate understanding by the editor and responses by the authors, reviewers are encouraged to organize concerns into numbered sections. Each section should include:\n\nA description of the concern\nWhere the issue occurs\nSeverity: Is this a threat to validity? Or is it a suggestion?\nHow to fix the issue, or how an editor would know if the issue has been fixed\n\nPlease put minor issues and typos into one “minor issues” section at the end of your review.\n\n\nIntentional Citations\nEach citation should have a clear purpose: to offload evidence or to build on existing progress.\n\nReferences should be used to explain the rationale, methods, and claims.\nAvoid telling authors to add references without stating what evidence or prior use that reference would support. A laundry list of references that “should be cited” is not helpful. If the reviewer wishes to suggest additional references, they must make a clear argument why.\nReferences can also be used to contrast the article with other very similar articles. However, this style of citation should be kept to a minimum and only used to clarify differences.\nA designated “Related Work” section is not required.\nMissing citations that could be easily remedied in revision is generally not grounds for rejection.\n\n\n\nDo’s and Don’ts\n\nIf you only have expertise in one facet of a multi-faceted paper, state what facets of the paper you were qualified to review. Example:_ My expertise is mostly in machine learning, so my review focuses on that part of the paper._\nAvoid “struggling to understand”. The difficulties could be one of the following issues:\n\nTechnical terms, theories, conceptual frameworks, or methods that you have inadequate knowledge of: Explicitly state the limitation of your expertise in the review form.\nVerbose or convoluted explanations: Precisely indicate which part(s) are verbose, convoluted, or confusing. Point out contradictions in the explanation, and suggest how the authors could improve them.\n\nTypos and grammatical mistakes: Pointing out typos and grammatical mistakes is a greatly appreciated service, though not required. However, unless the article has severe readability issues, typos should not negatively impact how the article’s content is reviewed. And a long list of typos is no substitute for a thorough review.\nAvoid assuming the nationality of the authors. Instead of saying “Have the paper proofread by a native speaker”, say that there are many grammatical mistakes and list a few examples.\nAvoid arbitrary heuristics (e.g., subject count, color palettes, or cutoffs of statistical measures) without explaining why failing to abide by them calls conclusions into question.\nAvoid prescribing preferred statistical approaches. If you say that a paper’s analysis or reporting needs to change, you should explain how their current approach fails to answer the questions the paper asks. Of course, you can request that a given approach is presented in a clear and transparent way.\nAvoid statements about the authors. The review should comment on and objectively critique the paper’s contribution, not the authors, their background, or their intent. Instead of “The authors failed to…”, write that “The paper does not…”.\nLimit the usage of opinionated statements (e.g., “I like”, “I dislike”) on issues that pertain to the validity of the paper. Instead, provide a substantial argument for your critique. Nevertheless, “I like” could still be used to complement stylistic and presentation choices."
  },
  {
    "objectID": "reviewer-guide.html#registered-reports",
    "href": "reviewer-guide.html#registered-reports",
    "title": "Reviewer guidelines",
    "section": "Registered Reports",
    "text": "Registered Reports\nA** registered report (RR)** is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS. This type of submission might not be suited for all kinds of visualization or HCI papers (see discussions here). Each reviewing phase of a registered report has to focus on different aspects of the submissions.\nAdditional methodological points such as suggesting an additional analysis or data collection that does not directly fit with the authors’ research question are encouraged but cannot be used to assess the validity of the submission and thus decide to reject or accept it. Once authors, reviewers, and editor(s) agree on the methodological plan, the submission is accepted in the first round.\nThe second round of reviewing aims at verifying that the plan has been followed by the authors in their data collection, analysis and reporting. Reviewers will thus carefully examine the report of the results and the conclusions drawn from the analysis to ensure that they fit the strength of evidence that the authors have gathered. In some cases, authors might have had to deviate from the plan they agreed to in the first stage of the RR. How to treat such deviations is currently an open question in the scientific landscape of venues accepting RRs and can only be assessed on a case-by-case basis. As our community further embraces RRs, we might be able to extract guidelines on the nature and criticality of deviations. Reviewers should thus re-read the methodology section which will highlight any and all deviations and reflect on the criticality of these deviations with respect to the evidence brought forward by the authoring team. The final recommendation should only depend on the deviations (if any) and the strength of the claims made in the results, discussions, and conclusion. The direction of the results themselves (even if null or negative) cannot be used as an argument to reject the manuscript or suggest changes.\nWe expect, in the case of deviations, that editors and reviewers will have to thoroughly discuss the implications they have on the final decision."
  },
  {
    "objectID": "reviewer-guide.html#possible-review-outcomes",
    "href": "reviewer-guide.html#possible-review-outcomes",
    "title": "Reviewer guidelines",
    "section": "Possible Review Outcomes",
    "text": "Possible Review Outcomes\nJoVI aims to advance knowledge. If the work is promising but still has not made the cut, reviewers and editors should encourage the authors to revise and resubmit. Rejections should be used sparingly. The following outcomes are possible at each stage:\nBefore sending out to external reviewers:\n\nDesk reject: The editor-in-chief may choose to desk-reject manuscripts that are clearly outside the scope of the journal, or not written in English. We may set more specific desk rejection criteria in the future; for feedback and discussion on this see issue #17.\nPre-review revision: If a manuscript misses the required components described in the author guidelines, or if the associate editor has other concerns (such as length not being commensurate with contribution), the editor may request the authors to make some revisions prior to sending the manuscript out to reviewers.\n\nAfter each round of review:\n\nReject: This decision will only be taken upon critical methodological, ethical, or technical flaws that cannot reasonably be fixed, even with major additional effort, or if the submission has not improved substantially over several revisions..\nMajor revision: In addition to critiques and suggestions, reviewers may also ask for clarifications in the major revision.\nMinor revision: Reviewers have reached a consensus that the required revisions could be checked by the editor without requiring further input from the external reviewers.\n\nAfter the final round of review:\n\nAccept: The content of the manuscript is considered final. No further changes are allowed without approval from the editor."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "To keep up with JoVI announcements, such as new papers or calls, subscribe to the general announcement mailing list or one of our social media channels below."
  },
  {
    "objectID": "news.html#mailing-list",
    "href": "news.html#mailing-list",
    "title": "News",
    "section": "Mailing List",
    "text": "Mailing List\n\nGeneral announcement mailing list"
  },
  {
    "objectID": "news.html#social-media",
    "href": "news.html#social-media",
    "title": "News",
    "section": "Social Media",
    "text": "Social Media\n\nPublication RSS Feed\nTwitter\nMastodon"
  },
  {
    "objectID": "author-guide.html",
    "href": "author-guide.html",
    "title": "Author guidelines",
    "section": "",
    "text": "Articles with different purposes take on different forms. All research articles are expected to comply with JOVI’s standards of validated and open evidence. Articles may fall under multiple types. Examples of different types of articles include:\nAn empirical research article draws generalizable or transferable conclusions about visualization and/or interaction using methods and results that have not been described or published in another peer-reviewed venue. Also in this type are replication studies that improve or challenge existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population). Further examples: empirical measurements, reanalyses, meta-analyses, systematic literature reviews.\nA registered report (RR) is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS.\nA systems or design research article extends what is possible in visualization and interactions, including interaction techniques, interactive systems, and tools. Articles in this type could also describe a design or engineering process that improves in, e.g., reusability, replicability, availability, efficiency, robustness, sustainability, or economy.\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo. For example, a commentary might describe concerns related to the methodology, analysis, interpretation, or generalization of previous work, or suggest new directions for the field as a whole. It does not need to collect any new evidence, as it simply needs to explain the issue. Comments may be about JOVI articles or any article related to visualization or human-computer interaction.\nA literature review or meta analysis article provides an overview over a subarea of our research field, by summarizing, contextualizing, and categorizing a (usually larger) body of previous work.\n\n\nJoVI does not accept work that has been published in other peer-reviewed journals or conferences or work that has been plagiarized without citation from other authors. Note that this is different from claims about the superficial novelty of a work.\nException: Because methods and procedures are not copyrightable (17 U.S. Code §102(b)), they may be copied from any source. However, the original work should be clearly cited."
  },
  {
    "objectID": "author-guide.html#what-types-of-articles-can-i-submit",
    "href": "author-guide.html#what-types-of-articles-can-i-submit",
    "title": "Author guidelines",
    "section": "",
    "text": "Articles with different purposes take on different forms. All research articles are expected to comply with JOVI’s standards of validated and open evidence. Articles may fall under multiple types. Examples of different types of articles include:\nAn empirical research article draws generalizable or transferable conclusions about visualization and/or interaction using methods and results that have not been described or published in another peer-reviewed venue. Also in this type are replication studies that improve or challenge existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population). Further examples: empirical measurements, reanalyses, meta-analyses, systematic literature reviews.\nA registered report (RR) is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS.\nA systems or design research article extends what is possible in visualization and interactions, including interaction techniques, interactive systems, and tools. Articles in this type could also describe a design or engineering process that improves in, e.g., reusability, replicability, availability, efficiency, robustness, sustainability, or economy.\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo. For example, a commentary might describe concerns related to the methodology, analysis, interpretation, or generalization of previous work, or suggest new directions for the field as a whole. It does not need to collect any new evidence, as it simply needs to explain the issue. Comments may be about JOVI articles or any article related to visualization or human-computer interaction.\nA literature review or meta analysis article provides an overview over a subarea of our research field, by summarizing, contextualizing, and categorizing a (usually larger) body of previous work.\n\n\nJoVI does not accept work that has been published in other peer-reviewed journals or conferences or work that has been plagiarized without citation from other authors. Note that this is different from claims about the superficial novelty of a work.\nException: Because methods and procedures are not copyrightable (17 U.S. Code §102(b)), they may be copied from any source. However, the original work should be clearly cited."
  },
  {
    "objectID": "author-guide.html#what-do-i-need-to-make-a-submission",
    "href": "author-guide.html#what-do-i-need-to-make-a-submission",
    "title": "Author guidelines",
    "section": "What do I need to make a submission?",
    "text": "What do I need to make a submission?\n\nSubmission template\nYou may use a template that you are familiar with, from IEEE, ACM, EuroGraphics, APA, or other well-known journals or conferences. We strongly recommend using either the IEEE or ACM single-column style for your submissions.\nHowever, JoVI has the following additional requirements:\n\nPaper size: Either ISO A4 or US-Letter.\nThe page orientation must be portrait.\nThe layout is single-column.\nLine heights for body text between 1.0x and 1.7x. Double-spaced body text, which is common in APA submissions, is not allowed.\nWe recommend 1.2x line spacing and a single column with 1.5-inch margins on the sides.\nFigures, tables, and their captions must be in the body text rather than all at the end.\n\n\n\nSections\nWe expect the following sections in the paper:\n\nAbstract\n(contents of the paper…)\nReferences\nResearch material statements*\nAuthorship*\nLicense\nConflict of interest*\nAppendices (optional)\n\nIf you wish to use anonymized review, ensure that all of the above sections in the paper are appropriately anonymized (e.g., for the Research materials section, include anonymized links to the research materials). Additionally, non-anonymized versions of the sections marked with (*) should be submitted as a separate PDF—which will be seen only by the editors.\n\nAbstract\nJOVI encourages you to use structured abstracts, with distinct, labeled sections for rapid comprehension. Here are examples of sections you may want to include in your abstract:\n\n\n\nIntroduction\n\n\n\nData collection\nImplementation\n\n\nData analysis\nDemonstration\n\n\nResults\nLessons learned\n\n\nMaterials\n\n\n\nConclusion\n\n\n\n\n\n\nResearch material statements\nProvide a URL to a repository containing raw data, open-source code, or (pre-)registrations, study materials, and any other supplemental materials or materials for reproducing this work. See Transparency and open research requirements for information on valid repositories below.\nIf materials cannot be shared at all or in the raw form, provide an explanation here.\n\n\nAuthorship\nArticles with multiple authors must describe the contributions of each author at the end of the article. Use the Contributor Roles Taxonomy (CRediT).\n\nA role may be performed by multiple authors\nNot all roles are needed for every article\nIf an author of your paper performed a role not listed in the CRediT taxonomy, you can add it, but please do so sparingly.\n\n\n\nLicense\nJOVI articles are published with a CC-BY license or CC-BY-SA license.\nFor a CC-BY license, include the following text in your initial submission:\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\nFor a CC-BY-SA license, include the following text in your initial submission:\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n\n\nConflicts of interest\nAll submissions must include a statement about potential conflicts of interest, including activities that potentially confer material or non-material rewards on the authors in connection with the topic of the article. The simplest example: “The authors declare that there are no competing interests.”\n\n\n\nPage length\nJoVI enforces no page limits on submissions. The page length of a paper should be commensurate with its contribution. Overly long papers are wasteful of the time of both readers and reviewers.\nThe corollary of this is that there is also no minimum page count for JoVI papers; short 2-page papers are encouraged if they represent small yet useful ideas of general value to the visualization and interaction community.\n\n\nDelivery format\nDeliver the article in one PDF file. If the paper will be reviewed anonymously, include a non-anonymized version in a separate PDF (this will not be released to reviewers)."
  },
  {
    "objectID": "author-guide.html#transparency-requirements",
    "href": "author-guide.html#transparency-requirements",
    "title": "Author guidelines",
    "section": "Transparency and open research requirements",
    "text": "Transparency and open research requirements\nJOVI has implemented “Level 2” of the Transparency and Openness Promotion guidelines, which requires openness and transparency of any data and procedures used to produce results.\nA summary table and the full guidelines are available from the Center for Open Science. Here is a brief overview:\n\nPreregistration: If a preregistration was made as part of the research, it must be reported. Any deviations or additional analyses must also be explained and reported as exploratory. Work without a preregistration must be reported as exploratory.\nData collection material: Any code, stimuli, questionnaires, or other materials used to collect empirical data must be provided along with instructions and documentation needed to replicate the procedure.\nEmpirical data: Any data collected as evidence must be reported in as raw a form as possible. Aggregation and preprocessing should be avoided unless there is a documented explanation. However, a “cleaned” or simplified version of the data may also be included for convenience.\nExceptions to this rule will only be granted in extraordinary cases, and only after careful ruling out of alternative options (e.g., adding noise to data to de-identify it).\nCode and analyses: Any code or analyses used to produce results must be provided and should be described and documented in enough detail to be easily reproduced.\n\n\nIf any of these artifacts are not used as part of the article (e.g., for a comment article), authors are of course not required to provide them.\n\nWhat if my data has private or personally identifiable information?\nYou can use a protected-access repository. See OSF’s list of protected access repositories.\nJOVI recommends Databrary. Although the description on their website emphasizes video and audio, they also accept other data types such as transcripts.\n\n\nWhere do I share code, data, and other materials?\nThe Open Science Framework is JOVI’s recommended repository for all supplemental material. Any repository that is compatible with the FAIR principles is also acceptable as long as the repository:\n\nprovides a unique immutable identifier\ntime-stamps each version or update\ncontent is interoperable and accessibly documented\nhas a long-term plan for persistence\n\nA list of many compliant repositories is available at www.re3data.org.\n\n\nNon-compliant repositories\n\nGithub: Github does not meet standards for persistence and immutability. However, you can use OSF (instructions) or Zenodo (instructions) to create a persistent copy of a Github Repository. Note that for OSF, you need to make a “registration” to archive the Github content; otherwise, it simply acts as a portal.\nPersonal or lab website: These websites are not immutable and are practically never persistent.\n\n\n\nWhat if my data is too large for OSF?\nOSF will work for files up to 1 GB. For larger datasets, try a service such as Data Dryad. Feel free to ask the editors for help.\n\n\nMaking the repository anonymous\nTo submit an OSF repository with an anonymous submission:\n\nEnsure that the repository is private\nCreate an anonymous version of a project.\nCreate a view-only link to an anonymous version of a preregistration."
  },
  {
    "objectID": "author-guide.html#anonymity-and-secrecy",
    "href": "author-guide.html#anonymity-and-secrecy",
    "title": "Author guidelines",
    "section": "Anonymity and secrecy",
    "text": "Anonymity and secrecy\nDuring the reviewing process, authors may choose to be anonymous or not. Reviewers may choose to sign their reviews or to remain anonymous. Editors will always know who the authors and the reviewers are.\nSharing preprints prior to submission is encouraged."
  },
  {
    "objectID": "author-guide.html#humane-and-transparent-reviewing",
    "href": "author-guide.html#humane-and-transparent-reviewing",
    "title": "Author guidelines",
    "section": "Humane and transparent reviewing",
    "text": "Humane and transparent reviewing\nJoVI aims for a collaborative, humane, and transparent review process. Reviewing is implemented as a (potentially anonymous) discussion between the authors and the reviewers rather than a one-sided argument about whether to accept or reject a manuscript.\n\nPre-review feedback: After initial submission, an action editor will perform a preliminary review to check for minor obvious problems. Broken URLs, formatting issues, a garbled figure, licensing concerns, and etc. may simply result in a request from the editor to resubmit a fixed version before it is sent out for review. You can resubmit as soon as the issue(s) is fixed.\nAccommodating both sides: After the initial pre-review feedback, editors will recruit reviewers and ask each of them to give a timeframe for their review. Generally, we aim for the first round of the reviews to be returned to the authors in around 6 weeks after the pre-review approval.\nNon-arbitrary: JoVI strives for reviews focused on the validity of claims and clarity of explanation. Reviews should also not rely on arbitrary thresholds such as minimum subject counts or maximum p-values.\nTypos happen: Typos or minor grammatical mistakes are inevitable, and they can be especially difficult to detect for people who do not have English as a native language. We strongly recommend that you carefully proofread your manuscript before submitting and after any revision. But as long as the manuscript is clear and understandable, these issues will not affect the score by reviewers. They may simply add an additional minor revision request.\nEditor review: Action editors check reviews before sending them to authors, and they may ask reviewers to rewrite a part of their review that comes across as overly personal. Should an author receive any personal or inappropriate comment in a review, they are encouraged to contact the editor or any member of the editorial board."
  },
  {
    "objectID": "author-guide.html#submission-instructions",
    "href": "author-guide.html#submission-instructions",
    "title": "Author guidelines",
    "section": "Submission instructions",
    "text": "Submission instructions\nSee How to submit."
  },
  {
    "objectID": "author-guide.html#publication",
    "href": "author-guide.html#publication",
    "title": "Author guidelines",
    "section": "Publication",
    "text": "Publication\nAfter a manuscript has been accepted by JoVI, it will be published through Aalborg University Press. The manuscript will receive a DOI. We are currently exploring the possibility of versioned DOIs, which will make it possible to submit updates to an existing article and turn it into a living, evolving document of the research process.\nWe recommend all authors read the reviewing guide for further information about the criteria and the reviewing process."
  },
  {
    "objectID": "organizers.html",
    "href": "organizers.html",
    "title": "Organizers",
    "section": "",
    "text": "To contact the JoVI organizing committee, email organizers@journalovi.org. For submission inquiries, email submit@journalovi.org.\nThe JoVI organizers (in alphabetical order) are:\nJoVI also owes a huge debt to Steve Haroz, who was instrumental in its formation and early iterations."
  },
  {
    "objectID": "organizers.html#advisory-board",
    "href": "organizers.html#advisory-board",
    "title": "Organizers",
    "section": "Advisory Board",
    "text": "Advisory Board\n\nPierre Dragicevic, Inria Bordeaux\nKasper Hornbæk, University of Copenhagen\nEva Hornecker, Bauhaus-Universität Weimar\nJessica Hullman, Northwestern University\nYvonne Jansen, CNRS\nAmelia McNamara, University of St Thomas\nArvind Satyanarayan, MIT CSAIL\nCarlos Scheidegger, Posit\nJon Schwabish, Urban Institute"
  },
  {
    "objectID": "organizers.html#associate-editors",
    "href": "organizers.html#associate-editors",
    "title": "Organizers",
    "section": "Associate Editors",
    "text": "Associate Editors\n\nLeilani Battle, University of Washington\nNiklas Elmqvist, University of Maryland, College Park\nLane Harrison, Worcester Polytechnic Institute\nYvonne Jansen, CNRS\nLace Padilla, University of California, Merced\nJon Schwabish, Urban Institute\nJason Dykes, City, University of London"
  },
  {
    "objectID": "organizers.html#publisher",
    "href": "organizers.html#publisher",
    "title": "Organizers",
    "section": "Publisher",
    "text": "Publisher\nAalborg University Press Kroghstræde 3 9220 Aalborg Ø DENMARK"
  }
]