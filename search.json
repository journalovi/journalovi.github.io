[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Journal of Visualization and Interaction",
    "section": "",
    "text": "The Journal of Visualization and Interaction (JoVI) is a venue for publishing scholarly work related to the fields of visualization and human-computer interaction. JoVI is a diamond open-access venue, i.e. a purely volunteer-driven effort that charges neither author nor subscription fees. Contributions to the journal include research in:\n\nhow people understand and interact with information and technology,\ninnovations in interaction techniques, interactive systems, or tools,\nsystematic literature reviews,\nreplication studies or reinterpretations of existing work,\nresearch software packages for HCI and visualization,\nand commentary on existing publications.\n\nCross-disciplinary work from other fields such as statistics or psychology, which is relevant to the fields of visualization or human-computer interaction is also welcome.\nJoVI’s missions are the following:"
  },
  {
    "objectID": "index.html#what-is-jovi",
    "href": "index.html#what-is-jovi",
    "title": "The Journal of Visualization and Interaction",
    "section": "",
    "text": "The Journal of Visualization and Interaction (JoVI) is a venue for publishing scholarly work related to the fields of visualization and human-computer interaction. JoVI is a diamond open-access venue, i.e. a purely volunteer-driven effort that charges neither author nor subscription fees. Contributions to the journal include research in:\n\nhow people understand and interact with information and technology,\ninnovations in interaction techniques, interactive systems, or tools,\nsystematic literature reviews,\nreplication studies or reinterpretations of existing work,\nresearch software packages for HCI and visualization,\nand commentary on existing publications.\n\nCross-disciplinary work from other fields such as statistics or psychology, which is relevant to the fields of visualization or human-computer interaction is also welcome.\nJoVI’s missions are the following:"
  },
  {
    "objectID": "index.html#open",
    "href": "index.html#open",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open by default",
    "text": "Open by default\nJoVI strongly supports transparency and openness and implements it as a default to enable readers to scrutinize and build on the research . All published manuscripts are open access. For any empirical components, manuscripts must make all data and reasoning available in ways that invite scrutiny, so that subsequent researchers can assess claims, reuse methods and materials, and build upon findings. For any computational components, all code needs to be reproducible within a reasonable effort. When ethical concerns prevent submissions to meet these requirements, the manuscript must clearly describe the characteristics of these artifacts and adequately justify the tradeoff between openness and ethics."
  },
  {
    "objectID": "index.html#open-review",
    "href": "index.html#open-review",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open review, comments, and continued conversation",
    "text": "Open review, comments, and continued conversation\nAll submitted work, reviews, and discussions will by default be publicly available for other researchers to use. To encourage accountability, editors’ names are listed on the articles they accept, and reviewers may choose to be named or anonymous . All submissions and their accompanying reviews and discussions remain accessible whether or not an article is accepted. To foster discussions that go beyond the initial reviewer/author exchanges, we welcome post-publication commentaries on articles."
  },
  {
    "objectID": "index.html#knowledge",
    "href": "index.html#knowledge",
    "title": "The Journal of Visualization and Interaction",
    "section": "Knowledge over novelty",
    "text": "Knowledge over novelty\nWe prioritize how research advances knowledge rather than superficial novelty. Reviews aim to evaluate the credibility of a manuscript’s claims and the clarity of its evidence. Contributions of interaction techniques or interactive systems may meet this knowledge criterion through existence proofs. For empirical works, JoVI encourages registered reports —the reviewing of study plans prior to execution—and has a process to support this type of contribution. The discourses on the merit of the manuscripts must be justified by evidence, credible literature, or cogent argument."
  },
  {
    "objectID": "index.html#humane",
    "href": "index.html#humane",
    "title": "The Journal of Visualization and Interaction",
    "section": "A more humane process, respectful of everyone’s time",
    "text": "A more humane process, respectful of everyone’s time\nJoVI respects the time and effort of both authors and reviewers, and aims for a collaborative, humane review process. To that end, JoVI does not publish a limited number of manuscripts and does not seek to have a certain rejection rate. Instead, review proceeds as a back and forth between authors and reviewers, with the goal of improving the work. Authors can expect that their submissions will not be rejected over easily fixable technicalities."
  },
  {
    "objectID": "index.html#ambitions",
    "href": "index.html#ambitions",
    "title": "The Journal of Visualization and Interaction",
    "section": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents",
    "text": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents\nIn addition to the missions above, JoVI also aspires to be a platform for other improvements of scholarly communication. On an alternate, optional submission track, we will continually experiment with new article formats (including modern, interactive formats), new review processes, and articles as living documents. This experimentation will be motivated by re-conceptualizing peer review as a humane, constructive process aimed at improving work rather than gatekeeping."
  },
  {
    "objectID": "index.html#acks",
    "href": "index.html#acks",
    "title": "The Journal of Visualization and Interaction",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the following people (in alphabetical order) who provided input on earlier versions of our mission statement: Leilani Battle, Pierre Dragicevic, Jason Dykes, Niklas Elmqvist, Jean-Daniel Fekete, Maximilian Häussler, Steve Haroz, Yvonne Jansen, Tamara Munzner, Kimberly Quinn, Raphael Wimmer."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "JoVI news and announcements are posted below. You can also keep up with JoVI via the following channels:"
  },
  {
    "objectID": "news.html#posts",
    "href": "news.html#posts",
    "title": "News",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "posts/2024-04-04-chi-sig/index.html",
    "href": "posts/2024-04-04-chi-sig/index.html",
    "title": "SIG @ CHI 2024",
    "section": "",
    "text": "Are you going to CHI 2024 and interested in experimenting with new review methods, open practices, and interactive publications in HCI? Join us in a SIG meeting hosted by JoVI (the Journal of Visualization and Interaction). We will specifically discuss topics surrounding the following question:\nWe want to hear from you: what would your ideal HCI publishing process look like? We will also share our experiences from the first year of JoVI, a diamond open-access, open review journal in HCI with an explicit mission to continually experiment with new review processes and publication models.\nThe main event will be a Special Interest Group meeting (SIG) at the CHI 2024 conference on 16 May 11:00 (Hawaiʻi time) in room 318A. We will also organize an online event synchronously at the same time."
  },
  {
    "objectID": "posts/2024-04-04-chi-sig/index.html#goals-of-the-event",
    "href": "posts/2024-04-04-chi-sig/index.html#goals-of-the-event",
    "title": "SIG @ CHI 2024",
    "section": "Goals of the event",
    "text": "Goals of the event\nAs part of this SIG, we want to reflect on the first year of JoVI, which was first announced at CHI 2023. We will present some initial lessons learned from reviewing our first few submissions (including two traditional articles and five interactive articles), as well as current challenges we face.\nWe want to better understand current situations, issues, opportunities, and perspectives around open publishing and reviewing in HCI. We aim to gather diverse perspectives from stakeholders representing various roles in the publishing process (academics, industry researchers, authors, editors, reviewers, and students) to help brainstorm about what HCI publication could look like.\nAttendees’ input will be gathered into a public document to be discussed by the JoVI advisory board at their annual meeting, and will inform the future directions of JoVI."
  },
  {
    "objectID": "posts/2024-04-04-chi-sig/index.html#how-to-attend",
    "href": "posts/2024-04-04-chi-sig/index.html#how-to-attend",
    "title": "SIG @ CHI 2024",
    "section": "How to attend",
    "text": "How to attend\n\nSIG meeting:\n\nIn-person: If you want to participate in person at CHI 2024 in Hawaiʻi on Thursday 16 May 11:00 (Hawaiʻi timezone) at room 318A, you can just drop by!\nOnline: If you want to participate online, please register here.\n\nRegardless of your participation, if you have any thoughts on open publishing or reviewing in HCI, or pointers to other works (e.g., papers, blog posts, newsletter articles, opinion statements) about open publishing and reviewing in HCI which you would like us to consider, please share with us by emailing to organizers@journalovi.org or by joining the Slack (see here)"
  },
  {
    "objectID": "posts/2024-04-04-chi-sig/index.html#please-spread-the-word",
    "href": "posts/2024-04-04-chi-sig/index.html#please-spread-the-word",
    "title": "SIG @ CHI 2024",
    "section": "Please spread the word",
    "text": "Please spread the word\nIf you know of other academics, researchers, students, or industry people who might be likely to give valuable input to this event, please let us know.\nIf you think your students or colleagues might be interested in attending this event, please forward them this post."
  },
  {
    "objectID": "under-review.html",
    "href": "under-review.html",
    "title": "Articles under review",
    "section": "",
    "text": "This page lists articles under review on the Experimental (“Github”) Track of JoVI. The experimental track uses an “endorsement” model, where review proceeds as a back-and-forth between reviewers and authors via Github issues, and then reviewers can choose whether or not to endorse the paper.\nThe articles below are still under review and have not yet received any endorsements. Feedback on these articles is welcome in the form of Github issues opened on their underlying repository.\n\nGatherplot: A Non-Overlapping Scatterplot[Repository | Reviews/Issues]\nReal time, cross platform visualizations with zero dependencies for the N-body package REBOUND[Repository | Reviews/Issues]\n\n\n\nThe articles below were originally part of VISxAI 2023 and are now under review for a special issue at JoVI:\n\nPAC Learning; Or: Why We Should (and Shouldn’t) Trust Machine Learning[Repository | Reviews/Issues]\nNeighborhood traces[Repository | Reviews/Issues]\nLearning What’s in a Name with Graphical Models[Repository | Reviews/Issues]"
  },
  {
    "objectID": "under-review.html#experimental-github-track",
    "href": "under-review.html#experimental-github-track",
    "title": "Articles under review",
    "section": "",
    "text": "This page lists articles under review on the Experimental (“Github”) Track of JoVI. The experimental track uses an “endorsement” model, where review proceeds as a back-and-forth between reviewers and authors via Github issues, and then reviewers can choose whether or not to endorse the paper.\nThe articles below are still under review and have not yet received any endorsements. Feedback on these articles is welcome in the form of Github issues opened on their underlying repository.\n\nGatherplot: A Non-Overlapping Scatterplot[Repository | Reviews/Issues]\nReal time, cross platform visualizations with zero dependencies for the N-body package REBOUND[Repository | Reviews/Issues]\n\n\n\nThe articles below were originally part of VISxAI 2023 and are now under review for a special issue at JoVI:\n\nPAC Learning; Or: Why We Should (and Shouldn’t) Trust Machine Learning[Repository | Reviews/Issues]\nNeighborhood traces[Repository | Reviews/Issues]\nLearning What’s in a Name with Graphical Models[Repository | Reviews/Issues]"
  },
  {
    "objectID": "under-review.html#traditional-track",
    "href": "under-review.html#traditional-track",
    "title": "Articles under review",
    "section": "Traditional Track",
    "text": "Traditional Track\nPapers on the Traditional Track are not listed on this page, as they are not public until they have been published."
  },
  {
    "objectID": "reviewer-guide.html",
    "href": "reviewer-guide.html",
    "title": "Reviewer guidelines",
    "section": "",
    "text": "Thank you for considering reviewing for the Journal of Visualization and Interaction (JoVI)! As with any peer-reviewed journal or conference, it is our volunteer reviewers who make it possible for us to publish valid and high-quality scientific papers. Reviewing for JoVI is in many ways the same as in reviewing for any other peer-reviewed venue. In this document, we will describe the overall review process, focusing in particular on topics that may be different from a typical journal or conference."
  },
  {
    "objectID": "reviewer-guide.html#before-agreeing-to-review",
    "href": "reviewer-guide.html#before-agreeing-to-review",
    "title": "Reviewer guidelines",
    "section": "Before Agreeing to Review",
    "text": "Before Agreeing to Review\n\nConfidentiality\nBy agreeing to review for JoVI, you also agree to maintain the confidentiality of all materials shared with you during the review process. Do not use any of the ideas, concepts, or techniques disclosed to you as part of the review process in your own research until they have been made public.\n\n\nAnonymity and Identity\nAuthors can choose to list their names or be anonymous during the reviewing process. We acknowledge the potential issues with unblinded review. For further discussion and feedback please see issue #16.\nA reviewer is still eligible to review if they know who the authors are due to seeing the work on social media or seeing a prior version of the work. However, reviewers should not “play detective” and actively seek anonymous author identities. In other words, please do not search for paper titles, open-source project names, or preprints during the review.\nExternal reviewers can choose to be named or to remain anonymous by simply choosing whether or not to sign their review (e.g., “signed, Jane Doe”). Signing reviews is encouraged, especially for thoughtful and thorough reviews.\nFor accountability, the action editor is not anonymous.\n\n\nConflicts of Interest\nPeer review is based on unbiased and fair reviewing practices. Conflicts of interest (COIs) are situations where a reviewer is unable to (or is perceived to be unable to) uphold a lack of bias and fairness. To prevent COIs from impacting the process, JoVI abides by the general ACM guidelines for conflicts of interest. Generally speaking, if you feel unable to give an unbiased and fair opinion on a submission given its authors or their affiliations, you should not review it.\nExample conflicts inappropriate for reviewing:\n\nPh.D. or postdoctoral mentor or mentee;\nFamily or close personal relationship;\nCo-author on a peer-reviewed paper within the last 2 years;\nCurrent collaborator on in-progress work or work under review; and\nAnyone at the same institution (excluding different branches or campuses).\nProfessional friendship or animosity."
  },
  {
    "objectID": "reviewer-guide.html#first-impression",
    "href": "reviewer-guide.html#first-impression",
    "title": "Reviewer guidelines",
    "section": "First Impression",
    "text": "First Impression\n\nPaper Length\nJoVI enforces no page limits or writing style on papers, but papers which are overly long or difficult to read are wasteful of both readers’ and reviewers’ time. The page length of a paper should be commensurate with its contribution, so reviewers are encouraged to point out parts of the submission that can be trimmed. The length of a manuscript should not however be used to recommend its rejection — rather it is a reason to suggest revision.\nThe corollary is that there is also no minimum page count for JoVI papers; short papers are encouraged if they represent succinctly described and useful ideas of general value to the visualization and interaction community."
  },
  {
    "objectID": "reviewer-guide.html#key-assessment-criteria",
    "href": "reviewer-guide.html#key-assessment-criteria",
    "title": "Reviewer guidelines",
    "section": "Key Assessment Criteria",
    "text": "Key Assessment Criteria\n\nKnowledge\nThe submission must prove its merit in advancing knowledge related to the fields of visualization and human-computer interaction. Knowledge advancement can be achieved in several ways, including but not limited to:\n\nEmpirical studies investigate research questions that have not been considered before\nReplication studies improve or challenge the confidence of the field about existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population, etc)\nSystems or design research expands the capacity of people to do useful things that were not previously possible\nSystematic literature reviews enables the field to synthesize knowledge across existing work\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo\n\n\n\nClaims and evidence\nWhen reviewing JoVI papers, focus on these questions about claims and evidence in the manuscript:\n\nAre the claims and research questions clearly communicated?\nAre the claims supported with evidence?\nMatch between claims and evidence: Does the provided evidence actually answer the question and support the claim? Does it support a stronger, weaker, or different claim? For example, if a paper only measures computational performance, it should not include claims about improved human behavioral performance.\nGeneralization and transfer: If the authors claim generalization or transfer beyond the evidence presented in the present studies: How strong are the arguments? How clear is the scope of generalization or transfer described?\nAnalytical validity: If there is any computational or statistical analysis, is it an appropriate match for the research question? Is it reported in an accurate and interpretable way?\n\nNote: While lack of novelty is not a concern at this journal, failure to contrast with very similar work may be problematic.\n\n\nOpenness and Transparency\nAll JoVI submissions are required to include all material needed to properly scrutinize and build on the research. For any empirical components, manuscripts must make all data and reasoning available in ways that invite scrutiny, so that subsequent researchers can assess claims, reuse methods and materials, and build upon findings. For any computational components, all code needs to be reproducible within a reasonable effort. When ethical concerns prevent submissions to meet these requirements, the manuscript must clearly describe the characteristics of these artifacts and adequately justify the tradeoff between openness and ethics.\nExamples of materials that should be included, except where justified as above: experiment code, software and hardware components of prototypes, stimuli, interview guides, transcripts, raw empirical data, analysis scripts, and URLs to preregistrations. For full details, see level 2 of the TOP guidelines (summary table and thefull guidelines).\nAs a reviewer, you are simply asked to check that the materials are present and accessible. You are encouraged (but not required) to check the validity of any part of the submission using its replication and reproducibility materials. If you do so, you should mention it in your review.\nIf you cannot access any of the material, you can stop the review to avoid wasting time. Tell the action editor immediately, and they will then contact the author to remedy the problem. The action editor will confirm, ask the authors to fix the problem, and reply to the reviewers once the review process can continue.\nUnder special circumstances, a submission may state the reason that material cannot be shared (e.g., for protecting participants’ identity). Such a statement must appear in the body of the paper. Reviewers and editors must make a judgment call as to whether the authors shared as much as possible and whether the rationale is acceptable.\nExamples:\n\nAcceptable: Sharing all of the data except subject-identifying columns.\nAcceptable: Putting any necessary identifiable information, transcripts, and recordings in a protected-access repository that requires following an ethical-vetting procedure to access.\nUnacceptable: Authors claim that material is their own intellectual property or will not share it due to commercial purposes.\nUnacceptable: Only sharing aggregated data and omitting the raw data and data aggregation code without stating why.\nUnacceptable: Authors told their IRB that they would not share the material despite it appearing fully anonymized."
  },
  {
    "objectID": "reviewer-guide.html#writing-your-review",
    "href": "reviewer-guide.html#writing-your-review",
    "title": "Reviewer guidelines",
    "section": "Writing Your Review",
    "text": "Writing Your Review\nJoVI reviews should be thorough but kind: aim for completeness and clarity of critique, but also think about how the authors will read your review (write the kind of review you would appreciate receiving). JoVI does not have a set rejection rate, so any work meeting our key criteria (above) should be a candidate for acceptance.\n\nModular Reviews\nTo facilitate understanding by the editor and responses by the authors, reviewers are encouraged to organize concerns into numbered sections. Each section should include:\n\nA description of the concern\nWhere the issue occurs\nSeverity: Is this a threat to validity? Or is it a suggestion?\nHow to fix the issue, or how an editor would know if the issue has been fixed\n\nPlease put minor issues and typos into one “minor issues” section at the end of your review.\n\n\nIntentional Citations\nEach citation should have a clear purpose: to offload evidence or to build on existing progress.\n\nReferences should be used to explain the rationale, methods, and claims.\nAvoid telling authors to add references without stating what evidence or prior use that reference would support. A laundry list of references that “should be cited” is not helpful. If the reviewer wishes to suggest additional references, they must make a clear argument why.\nReferences can also be used to contrast the article with other very similar articles. However, this style of citation should be kept to a minimum and only used to clarify differences.\nA designated “Related Work” section is not required.\nMissing citations that could be easily remedied in revision is generally not grounds for rejection.\n\n\n\nDo’s and Don’ts\n\nIf you only have expertise in one facet of a multi-faceted paper, state what facets of the paper you were qualified to review. Example: My expertise is mostly in machine learning, so my review focuses on that part of the paper.\nAvoid “struggling to understand”. The difficulties could be one of the following issues:\n\nTechnical terms, theories, conceptual frameworks, or methods that you have inadequate knowledge of: Explicitly state the limitation of your expertise in the review form.\nVerbose or convoluted explanations: Precisely indicate which part(s) are verbose, convoluted, or confusing. Point out contradictions in the explanation, and suggest how the authors could improve them.\n\nTypos and grammatical mistakes: Pointing out typos and grammatical mistakes is a greatly appreciated service, though not required. However, unless the article has severe readability issues, typos should not negatively impact how the article’s content is reviewed. And a long list of typos is no substitute for a thorough review.\nAvoid assuming the nationality of the authors. Instead of saying “Have the paper proofread by a native speaker”, say that there are many grammatical mistakes and list a few examples.\nAvoid arbitrary heuristics (e.g., subject count, color palettes, or cutoffs of statistical measures) without explaining why failing to abide by them calls conclusions into question.\nAvoid prescribing preferred statistical approaches. If you say that a paper’s analysis or reporting needs to change, you should explain how their current approach fails to answer the questions the paper asks. Of course, you can request that a given approach is presented in a clear and transparent way.\nAvoid statements about the authors. The review should comment on and objectively critique the paper’s contribution, not the authors, their background, or their intent. Instead of “The authors failed to…”, write that “The paper does not…”.\nLimit the usage of opinionated statements (e.g., “I like”, “I dislike”) on issues that pertain to the validity of the paper. Instead, provide a substantial argument for your critique. Nevertheless, “I like” could still be used to complement stylistic and presentation choices."
  },
  {
    "objectID": "reviewer-guide.html#registered-reports",
    "href": "reviewer-guide.html#registered-reports",
    "title": "Reviewer guidelines",
    "section": "Registered Reports",
    "text": "Registered Reports\nA registered report (RR) is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS. This type of submission might not be suited for all kinds of visualization or HCI papers (see discussions here). Each reviewing phase of a registered report has to focus on different aspects of the submissions.\nAdditional methodological points such as suggesting an additional analysis or data collection that does not directly fit with the authors’ research question are encouraged but cannot be used to assess the validity of the submission and thus decide to reject or accept it. Once authors, reviewers, and editor(s) agree on the methodological plan, the submission is accepted in the first round.\nThe second round of reviewing aims at verifying that the plan has been followed by the authors in their data collection, analysis and reporting. Reviewers will thus carefully examine the report of the results and the conclusions drawn from the analysis to ensure that they fit the strength of evidence that the authors have gathered. In some cases, authors might have had to deviate from the plan they agreed to in the first stage of the RR. How to treat such deviations is currently an open question in the scientific landscape of venues accepting RRs and can only be assessed on a case-by-case basis. As our community further embraces RRs, we might be able to extract guidelines on the nature and criticality of deviations. Reviewers should thus re-read the methodology section which will highlight any and all deviations and reflect on the criticality of these deviations with respect to the evidence brought forward by the authoring team. The final recommendation should only depend on the deviations (if any) and the strength of the claims made in the results, discussions, and conclusion. The direction of the results themselves (even if null or negative) cannot be used as an argument to reject the manuscript or suggest changes.\nWe expect, in the case of deviations, that editors and reviewers will have to thoroughly discuss the implications they have on the final decision."
  },
  {
    "objectID": "reviewer-guide.html#possible-review-outcomes",
    "href": "reviewer-guide.html#possible-review-outcomes",
    "title": "Reviewer guidelines",
    "section": "Possible Review Outcomes",
    "text": "Possible Review Outcomes\nJoVI aims to advance knowledge. If the work is promising but still has not made the cut, reviewers and editors should encourage the authors to revise and resubmit. Rejections should be used sparingly. The following outcomes are possible at each stage:\nBefore sending out to external reviewers:\n\nDesk reject: The editor-in-chief may choose to desk-reject manuscripts that are clearly outside the scope of the journal, or not written in English. We may set more specific desk rejection criteria in the future; for feedback and discussion on this see issue #17.\nPre-review revision: If a manuscript misses the required components described in the author guidelines, or if the associate editor has other concerns (such as length not being commensurate with contribution), the editor may request the authors to make some revisions prior to sending the manuscript out to reviewers.\n\nAfter each round of review:\n\nReject: This decision will only be taken upon critical methodological, ethical, or technical flaws that cannot reasonably be fixed, even with major additional effort, or if the submission has not improved substantially over several revisions..\nMajor revision: In addition to critiques and suggestions, reviewers may also ask for clarifications in the major revision.\nMinor revision: Reviewers have reached a consensus that the required revisions could be checked by the editor without requiring further input from the external reviewers.\n\nAfter the final round of review:\n\nAccept: The content of the manuscript is considered final. No further changes are allowed without approval from the editor."
  },
  {
    "objectID": "reviewer-guide.html#associate-editors",
    "href": "reviewer-guide.html#associate-editors",
    "title": "Reviewer guidelines",
    "section": "Associate Editors",
    "text": "Associate Editors\nIf you have been invited as an associate editor for JoVI, we also suggest looking through the following documents:\n\nIf you are involved in the traditional track, please look at the OJS Editorial Workflow documentation and the corresponding FAQ.\nIf you are involved in the experimental track, please have a look at and possibly comment on the Experimental Track Workflow."
  },
  {
    "objectID": "submit.html",
    "href": "submit.html",
    "title": "How to submit",
    "section": "",
    "text": "Submissions are handled by an Action Editor who will assign each submission to three expert reviewers. Review proceeds as a dialogue between authors and reviewers, with the goal of improving the work. Authors can expect that their submissions will not be rejected over easily fixable technicalities.\nAll submitted work, reviews, and discussions will by default be publicly available for other researchers to use. To encourage accountability, editors’ names are listed on the articles they accept, and reviewers may choose to be named or anonymous. All submissions and their accompanying reviews and discussions remain accessible whether or not an article is accepted.\nJoVI encourages registered reports, which follow a two-stage submission and review process. In the first stage, authors submit a paper that contains all plans, methods, and research questions, prior to any data collection. Through dialogue and discussion, reviewers and authors agree on revised plans, methods, and research questions. Then authors can collect and analyze data and write the final version of the paper, which will get a lightweight second-stage review by the same reviewers (except in extenuating circumstances).\nJoVI has two submission tracks: the traditional track and the experimental (“Github”) track."
  },
  {
    "objectID": "submit.html#traditional",
    "href": "submit.html#traditional",
    "title": "How to submit",
    "section": "Traditional track",
    "text": "Traditional track\nYou may prepare your paper with any academic paper template that you are familiar with, from IEEE, ACM, EuroGraphics, APA, or other well-known journals or conferences. However, we strongly recommend the ACM template or the IEEE TVCG template.\nJoVI has the following additional requirements:\n\nPaper size: Either ISO A4 or US-Letter.\nThe page orientation must be portrait.\nThe layout is single-column.\nLine heights for body text between 1.0x and 1.7x. Double-spaced body text, which is common in APA submissions, is not allowed.\nWe recommend 1.2x line spacing and a single column with 1.5-inch margins on the sides.\nFigures, tables, and their captions must be in the body text rather than all at the end.\n\nSubmission for the traditional track proceeds via the OJS submission system, hosted courtesy of the Aalborg University Library. Please create an OJS account, preferably using your default institutional email address, and follow the instructions on OJS to submit your paper and supplementary materials.\nTo submit:\n\nPlease read the Author Guidelines, even if you are a seasoned HCI/VIS researcher. JoVI’s process and expectations may be a bit different from what you are used to.\nStart:\n\nGo to JoVI’s OJS page\nCreate an account and/or log in, if needed\nComplete all submission requirements\nIf you are submitting anonymously, please indicate so in the Comments for the Editor section.\nClick Save and continue\n\nUpload submission:\n\nClick Add file, upload main PDF\nSelect “Article Text” as type\nIf you are submitting anonymously:\n\nThe version uploaded in the type “Article Text” must be the anonymous version. This version will be sent to reviewers.\nAdditionally, you may need to upload non-anonymous versions containing required sections. Please name your file with the prefix [non-anonymous]. After uploading it, select the type Only if you submit anonymously: Non-anonymized article text.\n\nUpload other files, if desired.\nClick Save and continue\n\nEnter Metadata:\n\nAdd title and abstract\nAdd co-authors: click add contributor, fill form\n\nSelect Author as role\nIf you create accounts for your co-authors, we recommend ticking Include contributor in browse lists so that co-authors’ accounts can be found later in search boxes.\n\nOptional: fill in extra metadata\nClick Save and continue\n\nConfirmation:\n\nClick Finish submission"
  },
  {
    "objectID": "submit.html#experimental",
    "href": "submit.html#experimental",
    "title": "How to submit",
    "section": "Experimental (“Github”) track",
    "text": "Experimental (“Github”) track\nThe experimental track is an alternative submission and review process that manifests our commitment to experimenting with review processes. This track is less well-defined, in part because we wish it to evolve with authors as we use it.\n\nSubmission format\nPapers on the “Github” track can be written in any format that renders to standalone HTML + Javascript. Some formats you might consider are:\n\nQuarto, a markdown-based computational notebook format. This is our recommended format. You can use the our Quarto template for JoVI articles. A live preview of this template is available here. Quarto is a plain text format that can be used with documents written in a variety of forms (RMarkdown, Jupyter notebook, Word, Latex), and supports embedded computation (in many languages, including R, Python, and Julia) and interactivity (using JavaScript / Observable, d3, etc).\nOther markdown-based notebook formats, such as:\n\nIdyll\nObservable Framework\n\nRaw HTML + JavaScript, perhaps using a template designed for scholarly articles, such as Distill.\nAny web workflow that renders to standalone HTML + JavaScript. We welcome experimentation!\n\nWe strongly prefer articles that do not require a live server. If your software requires server-side execution to work, see relevant instructions in the author guide.\nIf you are interested in trying another format and are not sure if it will work, open an issue on the jovi-submissions repository to ask about how we can help.\n\n\nHow to submit\nTo submit to the experimental track, create an article submission issue on the jovi-submissions repository.\n\n\nReview process\nAll review on the experimental track proceeds as Github issues, and published papers on this track can be updated using pull requests, even after publication. The Github repository for each submission will be public throughout the process, regardless of the final decision on the submission. Therefore, while withdrawal of a submission is possible (in the sense that authors can ask for their paper not to be considered “published” at JoVI), the submitted paper and reviews will still be public even if the submission is withdrawn or is not accepted."
  },
  {
    "objectID": "submit.html#reviewing-timeline",
    "href": "submit.html#reviewing-timeline",
    "title": "How to submit",
    "section": "Reviewing timeline",
    "text": "Reviewing timeline\nJoVI organizers process articles in batches at the end of each month, except March and September. Articles submitted by the end of last Friday (AoE) of each month will be processed in that month’s batch. The reviewing timeline is roughly as follows:\n\nAssociate editor assignment usually takes two weeks.\nReviewer invitation usually takes two weeks.\nAfter accepting the invitation, each reviewer has four–six weeks to write the review.\nAfter all reviews arrive, the associate editor may take two weeks to write their meta-review.\nThe reviewing process usually has more than one round."
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "To contact the JoVI organizing committee, email organizers@journalovi.org. For submission inquiries, email submit@journalovi.org."
  },
  {
    "objectID": "people.html#organizing-committee",
    "href": "people.html#organizing-committee",
    "title": "People",
    "section": "Organizing Committee",
    "text": "Organizing Committee\nThe JoVI organizers (in alphabetical order) are:\n\nLonni Besançon, Linköping University (Github ID: @lonnibesancon)\nFlorian Echtler, Aalborg University (Github ID: @floe)\nMatthew Kay, Northwestern University (Github ID: @mjskay)\nChat Wacharamanotham, University of Zurich (Github ID: @chatchavan)\n\nJoVI also owes a huge debt to Steve Haroz, who was instrumental in its formation and early iterations."
  },
  {
    "objectID": "people.html#advisory-board",
    "href": "people.html#advisory-board",
    "title": "People",
    "section": "Advisory Board",
    "text": "Advisory Board\n\nPierre Dragicevic, Inria Bordeaux\nJason Dykes, City, University of London\nJeffrey Heer, University of Washington\nKasper Hornbæk, University of Copenhagen\nEva Hornecker, Bauhaus-Universität Weimar\nJessica Hullman, Northwestern University\nYvonne Jansen, CNRS\nAmelia McNamara, University of St Thomas\nArvind Satyanarayan, MIT CSAIL\nCarlos Scheidegger, Posit\nJon Schwabish, Urban Institute"
  },
  {
    "objectID": "people.html#accessibility-chair",
    "href": "people.html#accessibility-chair",
    "title": "People",
    "section": "Accessibility Chair",
    "text": "Accessibility Chair\n\nDominik Moritz, Carnegie Mellon University (accessibility@journalovi.org)"
  },
  {
    "objectID": "people.html#associate-editors",
    "href": "people.html#associate-editors",
    "title": "People",
    "section": "Associate Editors",
    "text": "Associate Editors\n\nLeilani Battle, University of Washington\nCindy Xiong Bearfield, Georgia Institute of Technology\nJason Dykes, City, University of London\nFrank Elavsky, Carnegie Mellon University\nNiklas Elmqvist, Aarhus University\nJames Eagan, Institut Polytechnique de Paris\nLane Harrison, Worcester Polytechnic Institute\nYvonne Jansen, CNRS\nMiguel Nacenta, University of Victoria\nAndrew McNutt, University of Utah\nClemens Nylandsted Klokmose, Aarhus University\nHouda Lamqaddam, University of Amsterdam\nLace Padilla, Northeastern University\nEvan Peck, University of Colorado Boulder\nJon Schwabish, Urban Institute\nMichael Sedlmair, University of Stuttgart\nEmily Wall, Emory University\nWesley Willett, University of Calgary\nRaphael Wimmer, University of Regensburg\nJessica K. Witt, Colorado State University\nFumeng Yang, Northwestern University"
  },
  {
    "objectID": "people.html#publisher",
    "href": "people.html#publisher",
    "title": "People",
    "section": "Publisher",
    "text": "Publisher\nAalborg University Open Publishing Kroghstræde 1-3 9220 Aalborg Øst DENMARK\nISSN 2794-5502"
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "code-of-conduct.html#our-pledge",
    "href": "code-of-conduct.html#our-pledge",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "code-of-conduct.html#our-standards",
    "href": "code-of-conduct.html#our-standards",
    "title": "Code of conduct",
    "section": "Our standards",
    "text": "Our standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "code-of-conduct.html#enforcement-responsibilities",
    "href": "code-of-conduct.html#enforcement-responsibilities",
    "title": "Code of conduct",
    "section": "Enforcement responsibilities",
    "text": "Enforcement responsibilities\nCommunity leaders, including but not limited to the editorial board and associate editors, are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "code-of-conduct.html#scope",
    "href": "code-of-conduct.html#scope",
    "title": "Code of conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, acting as an appointed representative at an online or offline event, or posting public reviews, issues, or comments on submissions."
  },
  {
    "objectID": "code-of-conduct.html#enforcement",
    "href": "code-of-conduct.html#enforcement",
    "title": "Code of conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at the JoVI Code of Conduct Incident Report Form. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "code-of-conduct.html#enforcement-guidelines",
    "href": "code-of-conduct.html#enforcement-guidelines",
    "title": "Code of conduct",
    "section": "Enforcement guidelines",
    "text": "Enforcement guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\nCorrection\n\nCommunity Impact\nUse of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\n\n\nConsequence\nA private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. Editors may require that the language of a review or response be changed before allowing the message to proceed to other parties.\n\n\n\nWarning\n\nCommunity Impact\nA violation through a single incident or series of actions.\n\n\nConsequence\nA warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nTemporary ban\n\nCommunity Impact\nA serious violation of community standards, including sustained inappropriate behavior.\n\n\nConsequence\nA temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nPermanent ban\n\nCommunity Impact\nDemonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\n\n\nConsequence\nA permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "code-of-conduct.html#attribution",
    "href": "code-of-conduct.html#attribution",
    "title": "Code of conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about the Contributor Covenant, see the FAQ. Translations are available here."
  },
  {
    "objectID": "structured-abstract-examples.html",
    "href": "structured-abstract-examples.html",
    "title": "Examples of structured abstracts",
    "section": "",
    "text": "Below are several examples of structured abstracts written based on existing papers in order to demonstrate their use.\nSee the top of the JoVI article template for the structured abstract template."
  },
  {
    "objectID": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "href": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "title": "Examples of structured abstracts",
    "section": "Perceptual proxies (empirical)",
    "text": "Perceptual proxies (empirical)\nBased on Perceptual proxies for extracting averages in data visualization\n\nIntroduction\nAcross science, education, and business, we process and communicate data visually. One bedrock finding in data visualization research is a hierarchy of precision for perceptual encodings of data, e.g., that encoding data with Cartesian positions allows more precise comparisons than encoding with sizes. But this hierarchy has only been tested for single value comparisons, under the assumption that those lessons would extrapolate to multi-value comparisons.\n\n\nData Collection or Source\nWe ran four within-subject behavioral experiments (three preregistered) to measure subjects’ ability to differentiate single values or set averages. The experiments used a staircase method to measure accuracy when comparing pairs of dot plots (position), floating bar graphs (length), or regular bar graphs (position + length).\n\n\nData Analysis\nWe used the stopping point of the staircase to estimate the just noticeable difference and ran within-subject anovas and t-test to estimate differences between (1) chart types, (2) single values vs. set averages, and (3) set sizes.\n\n\nAnalysis Results\nResults include: (1) Confirming known findings in the visualization literature, the results showed that single-value comparison was least precise with floating bar graphs (length only). (2) However, when comparing averages across multiple data points, the discriminability was indistinguishable between chart types. (3) An exploratory analysis found that comparisons between different set sizes reduced accuracy but not reliably for all chart types.\n\n\nConclusion\nViewers compare values using surprisingly primitive perceptual cues, e.g., the summed area of bars in a bar graph. These results highlight a critical need to study a broader constellation of visual cues that mediate the patterns that we can see in data, across visualization types and tasks.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "href": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "title": "Examples of structured abstracts",
    "section": "Open practices in vis (empirical)",
    "text": "Open practices in vis (empirical)\nBased on Open practices in visualization research\n\nIntroduction\nTwo fundamental tenets of scientific research are that it can be scrutinized and built-upon. Both require that the collected data and supporting materials be shared, so others can examine, reuse, and extend them. Assessing the accessibility of these components and the paper itself can serve as a proxy for the reliability, replicability, and applicability of a field’s research.\n\n\nData Collection or Source\nI checked all papers published in VIS in 2017 to see which were available on a preprint repository, included a preregistration, included data collection materials, included raw data, or included computation/analysis materials.\n\n\nData Analysis\nIn an exploratory analysis of all VIS publications in 2017, I calculated the proportion of papers with a preprint and open practices on a reliable open access repository or a website without long-term availability.\n\n\nAnalysis Results\nA minority of published articles are available on an open access server, and extremely few included additional research materials on an open and reliable repository. The availability also varied by conference track.\n\n\nConclusion\nThe lack of open practices may severely hamper the ability to scrutinize, replicate, or reproduce visualization research. The paper provides suggestions for authors, reviewers, and editors to improve the poor state of open practices in the field.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#explorable-multiverse-technique",
    "href": "structured-abstract-examples.html#explorable-multiverse-technique",
    "title": "Examples of structured abstracts",
    "section": "Explorable multiverse (technique)",
    "text": "Explorable multiverse (technique)\nBased on Increasing the Transparency of Research Papers with Explorable Multiverse Analyses\n\nIntroduction\nWe present explorable multiverse analysis reports (EMARs), a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two ideas: multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation.\n\n\nImplementation\nWe use R scripts to build EMARs by pre-computing analysis results from every universe from a combination of all analysis parameters in a given multiverse. The output from those scripts is then presented using interactive HTML+JavaScript templates.\n\n\nDemonstration\nWe prototype five example EMARs by re-analyzing existing papers and building interactive papers to demonstrate different interactive approaches to communicating multiverses. We show how combining multiverse analysis and explorable explanations might complement existing reporting approaches and constitute a step towards more transparent research papers.\nBased on these examples and existing literature on multiverse analysis, we develop a design space for multiverse analysis reports. Our design space describes analysis parameters, analysis options, and multiplexing and aggregation techniques for summarizing and communicating multiverses. We identify several challenges to multiverse construction, including identifying simple end goals that can be multiplexed across universes (which can be easier with single statistics than entire plots, for example), and provide recommendations for writing conclusions in papers that span multiverses (to avoid authors/readers simply selecting desired results).\n\n\nConclusion\nThe development of tools to facilitate the multiverse analysis process within analysts’ workflows remains a substantial challenge: our prototypes consist of custom R scripts and HTML templates that require significant technical expertise to develop. Automating these workflows for data analysts is an important next step.\n\n\nMaterials\nSee live demo here. [NOTE: for JoVI, a backup link to a permanent repository should also be included with live demo links]"
  },
  {
    "objectID": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "href": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "title": "Examples of structured abstracts",
    "section": "BinarySwipes (technique + user study)",
    "text": "BinarySwipes (technique + user study)\nBased on BinarySwipes: Fast List Search on Small Touchscreens (straightforward UI technique & user study) [Florian]\n\nIntroduction\nWe present BinarySwipes, an interaction technique based on binary search which is designed to speed up list search tasks on space-constrained touchscreens.\nSmartwatches and other wearables generally have small screens, thereby complicating touch-based interaction. Selection from a long list, eg to locate a contact or a music track, is particularly cumbersome due to the limited interaction space.\n\n\nImplementation\nTBD\n\n\nDemonstration\nTBD\n\n\nData Collection or Source\nWe evaluate a prototypical implementation of BinarySwipes on a smartwatch with 21 participants in a controlled user study. We measure task completion time, error rate, and self-reported NASA TLX values.\n\n\nData Analysis\nWe analyze our data with respect to normal distribution (Shapiro-Wilk) and statistically significant differences between conditions (ANOVA with post-hoc Tukey HSD, Bonferroni correction).\n\n\nAnalysis Results\nResults from our evaluation show improved performance over a plain linear search on lists with 100, 200 and 500 entries, but also increased mental load on the users.\n\n\nConclusion\nBinarySwipes is a viable technique for quickly locating known items in long lists, but challenges remain for exploratory search, or when the presence of the item is not known in advance.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "posts/2023-08-26-summer-2023-updates/index.html",
    "href": "posts/2023-08-26-summer-2023-updates/index.html",
    "title": "Summer 2023 Updates",
    "section": "",
    "text": "The summer break is winding down, and we would like to give you an update about what’s going on at the new Journal of Visualization and Interaction.\nFirst of all, we have our very first submission for the experimental track currently being reviewed. As the experimental track also exists to experiment with open reviews (among other things), you can follow the process along at Github. The interactive article draft can also be found online.\nIn addition, we have agreed with two external academic venues, namely the VISxAI workshop at IEEE VIS 2023 and the Information+ Conference 2023, to act as publication venue for the extended versions of their proceedings. These articles will be subject to the same openness requirements as other JoVI submissions, and will go through a second round of reviews before being accepted into the corresponding special issue.\nIf you have further questions about JoVI, feel free to contact us via email, join our Transparent Research Slack channel, or ping us on Twitter and Mastodon."
  },
  {
    "objectID": "author-guide.html",
    "href": "author-guide.html",
    "title": "Author guidelines",
    "section": "",
    "text": "Articles with different purposes take on different forms. All research articles are expected to comply with JoVI’s standards of validated and open evidence. Articles may fall under multiple types. Examples of different types of articles include:\nAn empirical research article draws generalizable or transferable conclusions about visualization and/or interaction using methods and results that have not been described or published in another peer-reviewed venue. Also in this type are replication studies that improve or challenge existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population). Further examples: empirical measurements, reanalyses, meta-analyses, systematic literature reviews.\nA registered report (RR) is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS.\nA systems or design research article extends what is possible in visualization and interactions, including interaction techniques, interactive systems, and tools. Articles in this type could also describe a design or engineering process that improves in, e.g., reusability, replicability, availability, efficiency, robustness, sustainability, or economy.\nResearch software packages are frameworks, libraries, or toolkits that are designed to be used by researchers in the visualization and interaction communities. Examples include R packages with new visualization types, software for guiding novices through statistical analysis, or frameworks to ease development effort for multi-device mixed-reality applications.\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo. For example, a commentary might describe concerns related to the methodology, analysis, interpretation, or generalization of previous work, or suggest new directions for the field as a whole. It does not need to collect any new evidence, as it simply needs to explain the issue. Comments may be about JOVI articles or any article related to visualization or human-computer interaction.\nA literature review or meta analysis article provides an overview over a subarea of our research field, by summarizing, contextualizing, and categorizing a (usually larger) body of previous work.\n\n\nJoVI does not accept work that has been published in other peer-reviewed journals or conferences or work that has been plagiarized without citation from other authors. Note that this is different from claims about the superficial novelty of a work.\nException: Because methods and procedures are not copyrightable (17 U.S. Code §102(b)), they may be copied from any source. However, the original work should be clearly cited."
  },
  {
    "objectID": "author-guide.html#what-types-of-articles-can-i-submit",
    "href": "author-guide.html#what-types-of-articles-can-i-submit",
    "title": "Author guidelines",
    "section": "",
    "text": "Articles with different purposes take on different forms. All research articles are expected to comply with JoVI’s standards of validated and open evidence. Articles may fall under multiple types. Examples of different types of articles include:\nAn empirical research article draws generalizable or transferable conclusions about visualization and/or interaction using methods and results that have not been described or published in another peer-reviewed venue. Also in this type are replication studies that improve or challenge existing knowledge through better methodology than the original studies (e.g., higher statistical power, improved methods, new population). Further examples: empirical measurements, reanalyses, meta-analyses, systematic literature reviews.\nA registered report (RR) is a subtype of the empirical research articles with two stages: In the initial submission, the motivation, methods, and potential interpretation of methods are described, but the data collection has not yet been performed. The reviewers can evaluate and recommend revision prior to the authors collecting data. Once the initial stage is accepted, the authors can run the study knowing that the results will not impact whether the study is published. The second stage of review primarily checks that the authors stuck to the original plan, documented any deviations, and drew appropriate conclusions. For more information, see Registered Reports at COS.\nA systems or design research article extends what is possible in visualization and interactions, including interaction techniques, interactive systems, and tools. Articles in this type could also describe a design or engineering process that improves in, e.g., reusability, replicability, availability, efficiency, robustness, sustainability, or economy.\nResearch software packages are frameworks, libraries, or toolkits that are designed to be used by researchers in the visualization and interaction communities. Examples include R packages with new visualization types, software for guiding novices through statistical analysis, or frameworks to ease development effort for multi-device mixed-reality applications.\nCommentary enables the field to recognize unseen phenomena, see new perspectives, or challenge the status quo. For example, a commentary might describe concerns related to the methodology, analysis, interpretation, or generalization of previous work, or suggest new directions for the field as a whole. It does not need to collect any new evidence, as it simply needs to explain the issue. Comments may be about JOVI articles or any article related to visualization or human-computer interaction.\nA literature review or meta analysis article provides an overview over a subarea of our research field, by summarizing, contextualizing, and categorizing a (usually larger) body of previous work.\n\n\nJoVI does not accept work that has been published in other peer-reviewed journals or conferences or work that has been plagiarized without citation from other authors. Note that this is different from claims about the superficial novelty of a work.\nException: Because methods and procedures are not copyrightable (17 U.S. Code §102(b)), they may be copied from any source. However, the original work should be clearly cited."
  },
  {
    "objectID": "author-guide.html#what-do-i-need-to-make-a-submission",
    "href": "author-guide.html#what-do-i-need-to-make-a-submission",
    "title": "Author guidelines",
    "section": "What do I need to make a submission?",
    "text": "What do I need to make a submission?\n\nSubmission template\nYou may use a template that you are familiar with, from IEEE, ACM, EuroGraphics, APA, or other well-known journals or conferences. We strongly recommend using either the IEEE or ACM single-column style for your submissions.\nHowever, JoVI has the following additional requirements:\n\nPaper size: Either ISO A4 or US-Letter.\nThe page orientation must be portrait.\nThe layout is single-column.\nLine heights for body text between 1.0x and 1.7x. Double-spaced body text, which is common in APA submissions, is not allowed.\nWe recommend 1.2x line spacing and a single column with 1.5-inch margins on the sides.\nFigures, tables, and their captions must be in the body text rather than all at the end.\n\n\n\nSections\nWe expect the following sections in the paper:\n\nAbstract\n(contents of the paper…)\nReferences\nResearch material statements*\nAuthorship*\nLicense\nConflict of interest*\nAppendices (optional)\n\nIf you wish to use anonymized review, ensure that all of the above sections in the paper are appropriately anonymized (e.g., for the Research materials section, include anonymized links to the research materials). Additionally, non-anonymized versions of the sections marked with (*) should be submitted as a separate PDF—which will be seen only by the editors.\n\nAbstract\nWe highly recommend all JoVI articles use a structured abstract. Structured abstracts provide a succinct overview of an article using a common set of sections. Which sections are used depends on the type of research and its goals. For example, articles with empirical methods should have a data collection section, while articles that do not analyze data to support a conclusion do not need such a section.\nYour paper may fall into multiple types of work. We provide some example sections you may want to include in your structured abstract in the JoVI article template, depending on the type of work (while that template is written for the experimental track, similar structured abstracts can be used for papers written on the traditional track). You can use the example sections to fill in the subsections that apply to your paper, then delete these first two paragraphs and the subsections that do not apply to your paper. Please add, merge, rename, or re-order sections if you feel that would improve clarity. See also (partial) examples of structured abstracts.\n\n\nReferences\nFor any reference entry that has a DOI, please append the DOI URL (prefixed with https://doi.org/) at the end of the reference entry. For example, see the last part of the following citation:\n\nBesançon, Lonni, Anastasia Bezerianos, Pierre Dragicevic, Petra Isenberg, and Yvonne Jansen. 2021. “Publishing Visualization Studies as Registered Reports: Expected Benefits and Researchers’ Attitudes.” https://doi.org/10.31219/osf.io/3z7kx.\n\nThis DOI URL allows CrossRef to recognize the references correctly. This issue is essential because some institutions still use citation counts from CrossRef for hiring or promotion.\n\n\nResearch material statements\nProvide a URL to a repository containing raw data, open-source code, or (pre-)registrations, study materials, and any other supplemental materials or materials for reproducing this work. See Transparency and open research requirements for information on valid repositories below.\nIf materials cannot be shared at all or in the raw form, provide an explanation here.\n\n\nAuthorship\nArticles with multiple authors must describe the contributions of each author at the end of the article. Use the Contributor Roles Taxonomy (CRediT).\n\nA role may be performed by multiple authors\nNot all roles are needed for every article\nIf an author of your paper performed a role not listed in the CRediT taxonomy, you can add it, but please do so sparingly.\n\nAn example authorship statement might read:\n\nAggie Eilwen: Investigation, Data Curation, Writing – Original Draft; Pedro Ellar: Writing – Review & Editing; Alena Ennio: Writing – Review & Editing, Supervision, Funding Acquisition.\n\n\n\nLicense\nJOVI articles are published with a CC-BY license or CC-BY-SA license.\nFor a CC-BY license, include the following text in your initial submission:\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\nFor a CC-BY-SA license, include the following text in your initial submission:\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\nFigures may be exempted from the CC-BY(-SA) licensing requirement, in which case they should have a copyright statement in their caption. However, we encourage CC-BY(-SA) licensing of figures if possible.\n\n\nConflicts of interest\nAll submissions must include a statement about potential conflicts of interest, including activities that potentially confer material or non-material rewards on the authors in connection with the topic of the article. The simplest example: “The authors declare that there are no competing interests.”\n\n\n\nPage length\nJoVI enforces no page limits on submissions. The page length of a paper should be commensurate with its contribution. Overly long papers are wasteful of the time of both readers and reviewers.\nThe corollary of this is that there is also no minimum page count for JoVI papers; short 2-page papers are encouraged if they represent small yet useful ideas of general value to the visualization and interaction community.\n\n\nDelivery format\nTraditional track: Deliver the article in one PDF file. If the paper will be reviewed anonymously, include a non-anonymized version in a separate PDF (this will not be released to reviewers). Experimental (“Github”) track: See How to submit page"
  },
  {
    "objectID": "author-guide.html#transparency-requirements",
    "href": "author-guide.html#transparency-requirements",
    "title": "Author guidelines",
    "section": "Transparency and open research requirements",
    "text": "Transparency and open research requirements\nJOVI has implemented “Level 2” of the Transparency and Openness Promotion guidelines, which requires openness and transparency of any data and procedures used to produce results.\nA summary table and the full guidelines are available from the Center for Open Science. Here is a brief overview:\n\nPreregistration: If a preregistration was made as part of the research, it must be reported. Any deviations or additional analyses must also be explained and reported as exploratory. Work without a preregistration must be reported as exploratory.\nData collection material: Any code, stimuli, questionnaires, or other materials used to collect empirical data must be provided along with instructions and documentation needed to replicate the procedure.\nEmpirical data: Any data collected as evidence must be reported in as raw a form as possible. Aggregation and preprocessing should be avoided unless there is a documented explanation. However, a “cleaned” or simplified version of the data may also be included for convenience.\nExceptions to this rule will only be granted in extraordinary cases, and only after careful ruling out of alternative options (e.g., adding noise to data to de-identify it).\nCode and analyses: Any code or analyses used to produce results must be provided and should be described and documented in enough detail to be easily reproduced.\n\n\nIf any of these artifacts are not used as part of the article (e.g., for a comment article), authors are of course not required to provide them.\n\nWhat if my data has private or personally identifiable information?\nYou can use a protected-access repository. See OSF’s list of protected access repositories.\nJOVI recommends Databrary. Although the description on their website emphasizes video and audio, they also accept other data types such as transcripts.\n\n\nWhere do I share code, data, and other materials?\nThe Open Science Framework is JOVI’s recommended repository for all supplemental material. Any repository that is compatible with the FAIR principles is also acceptable as long as the repository:\n\nprovides a unique immutable identifier\ntime-stamps each version or update\ncontent is interoperable and accessibly documented\nhas a long-term plan for persistence\n\nA list of many compliant repositories is available at www.re3data.org.\n\n\nNon-compliant repositories\n\nGithub: Github does not meet standards for persistence and immutability. However, you can use OSF (instructions) or Zenodo (instructions) to create a persistent copy of a Github Repository. Note that for OSF, you need to make a “registration” to archive the Github content; otherwise, it simply acts as a portal.\nPersonal or lab website: These websites are not immutable and are practically never persistent.\n\n\n\nWhat if my data is too large for OSF?\nOSF will work for files up to 1 GB. For larger datasets, try a service such as Data Dryad. Feel free to ask the editors for help.\n\n\nMaking the repository anonymous\nTo submit an OSF repository with an anonymous submission:\n\nEnsure that the repository is private\nCreate an anonymous version of a project.\nCreate a view-only link to an anonymous version of a preregistration.\n\n\n\nSupplementary repository vs. paper repository\nSupplementary materials mentioned in this section are on a repository maintained by the author. This “supplementary repository” is separated from the “paper repository”—which JoVI creates on GitHub for each paper. This separation of ownership allows the authors to use their supplementary repository for (1) past/future papers on the same line of research, (2) keeping the preregistration records that were done prior to submission. The paper repository enables JoVI continuous and open reviewing process.\n\n\nWhat if my interactive article requires server-side execution?\nWe prefer self-contained web applications as they will likely remain working in the long run. It may be possible to make your software self-contained as a WebAssembly application. See ongoing work in R and Python. However, there could be situations where the solutions above do not work or are unsuitable, e.g., works that require heavy computation.\nIf server-side execution is unavoidable, we expect the following in your submission:\n\nYour primary submission will be a “lite” version that can demonstrate the essence of the work in a self-contained package (HTML + Javascript). Upon publication, only the lite version will be archived by JoVI.\nThe full version must be accessible to reviewers and editors throughout the reviewing process. After publication, maintaining the full version is at the authors’ discretion.\nA Docker file that allows your server-side infrastructure to be reproduced\n\n\n\nI analyzed my data via a GUI and do not have analysis code.\nMany GUI-based statistical software actually keep track of what you did in code that you can export, e.g., [SPSS], [JMP]. If your software does not provide script exports, please capture the steps that you went through as detailed as you can (e.g., indicate which options were checked or not, or provide screenshots). As a last resort, describe the statistical methods that you use in as much detail as you can.\nLastly, once you have the data in the table ready for GUI statistical software, running the analysis in R is only 2–3 lines of code. Many tutorials are accessible free of charge over the internet, e.g., Koji Yatani’s and Jacob Wobbrock’s, and Hadley Wickham et al.."
  },
  {
    "objectID": "author-guide.html#anonymity-and-secrecy",
    "href": "author-guide.html#anonymity-and-secrecy",
    "title": "Author guidelines",
    "section": "Anonymity and secrecy",
    "text": "Anonymity and secrecy\nDuring the reviewing process, authors may choose to be anonymous or not. Reviewers may choose to sign their reviews or to remain anonymous. Editors will always know who the authors and the reviewers are. Potential editors may also see who the authors are during editor recruitment.\nSharing preprints prior to submission is encouraged."
  },
  {
    "objectID": "author-guide.html#humane-and-transparent-reviewing",
    "href": "author-guide.html#humane-and-transparent-reviewing",
    "title": "Author guidelines",
    "section": "Humane and transparent reviewing",
    "text": "Humane and transparent reviewing\nJoVI aims for a collaborative, humane, and transparent review process. Reviewing is implemented as a (potentially anonymous) discussion between the authors and the reviewers rather than a one-sided argument about whether to accept or reject a manuscript.\n\nPre-review feedback: After initial submission, an action editor will perform a preliminary review to check for minor obvious problems. Broken URLs, formatting issues, a garbled figure, licensing concerns, and etc. may simply result in a request from the editor to resubmit a fixed version before it is sent out for review. You can resubmit as soon as the issue(s) is fixed.\nAccommodating both sides: After the initial pre-review feedback, editors will recruit reviewers and ask each of them to give a timeframe for their review. Generally, we aim for the first round of the reviews to be returned to the authors in around 6 weeks after the pre-review approval.\nNon-arbitrary: JoVI strives for reviews focused on the validity of claims and clarity of explanation. Reviews should also not rely on arbitrary thresholds such as minimum subject counts or maximum p-values.\nTypos happen: Typos or minor grammatical mistakes are inevitable, and they can be especially difficult to detect for people who do not have English as a native language. We strongly recommend that you carefully proofread your manuscript before submitting and after any revision. But as long as the manuscript is clear and understandable, these issues will not affect the score by reviewers. They may simply add an additional minor revision request.\nEditor review: Action editors check reviews before sending them to authors, and they may ask reviewers to rewrite a part of their review that comes across as overly personal. Should an author receive any personal or inappropriate comment in a review, they are encouraged to contact the editor or any member of the editorial board."
  },
  {
    "objectID": "author-guide.html#submission-instructions",
    "href": "author-guide.html#submission-instructions",
    "title": "Author guidelines",
    "section": "Submission instructions",
    "text": "Submission instructions\nSee How to submit."
  },
  {
    "objectID": "author-guide.html#publication",
    "href": "author-guide.html#publication",
    "title": "Author guidelines",
    "section": "Publication",
    "text": "Publication\nAfter a manuscript has been accepted by JoVI, it will be published through Aalborg University Press. The manuscript will receive a DOI. We are currently exploring the possibility of versioned DOIs, which will make it possible to submit updates to an existing article and turn it into a living, evolving document of the research process.\nWe recommend all authors read the reviewing guide for further information about the criteria and the reviewing process."
  }
]